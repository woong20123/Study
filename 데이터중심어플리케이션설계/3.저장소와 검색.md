# 저장소와 검색
* 데이터 베이스의 기본적인 작업은 데이터를 저장하고 데이터를 요청하면 다시 데이터를 전달하는 것입니다. 
* 그렇다면 데이터 베이스 입장에서 어떻게 해당 기능을 제공하는지 알아봅니다. 
* 이번장에서는 관계형 DB와 NOSQL의 저장소 엔진에 대해서 알아봅니다.
* 추가로 로그 구조계정의 저장소 엔진과 페이지 지향(B-tree같은) 계열 저장소 엔진을 검토합니다.
  
## 데이터베이스를 강력하게 만드는 데이터 구조
* 많은 데이터 베이스는 append-only 데이터 파일인 log를 사용합니다. 
  * log를 구현하기 위해서는 동시성 제어, 로그 크기 제어를 위한 회수 작업, 오류 처리 부분 기록된 레코드 처리등의 문제가 해결되어야함
  * log라는 단어는 애플리케이션에서 무슨일이 일어났는지 기술한 정보입니다. 
* 데이터 베이스에서 매번 값을 찾을 때마다 full scan을 하게 되면 데이터가 많은 경우 성능이 매우 감소합니다. 
* 데이터 베이스에서 특정 키를 효율적으로 찾기 위해서 index를 사용합니다. 
* index는 일반적으로 부가적인 메타 테이터를 유지합니다. 
  * mysql의 index page같이 데이터의 위치를 찾는데 도움을 줍니다. 
* index는 데이터 베이스의 값에는 영향을 미치지 않고 질의 성능에만 영향을 줍니다. 
* index는 특히 쓰기 과정에서 오버헤드가 발생합니다 
  * 왜냐하면 데이터를 쓸때 마다 인덱스도 업데이트 해주기 때문입니다. 
* 그러므로 인덱스를 선택할 때는 최소한의 비용으로 최대의 이익을 안겨줄수 있는 선택을 하는 것이 중요합니다. 

### 해시 색인
* 일반적으로 key-value 데이터는 해시 맵을 통해서 구현합니다. 
#### 파일의 바이트 offset을 이용한 해시 맵
* append-only를 통해서 데이터를 관리한다고 하면 key를 파일의 바이트 offset과 매핑해서 인메모리 해시 맵을 유지 할 수 있음
* 파일에 새로운 key-value가 추가 될 때마다 기록한 데이터의 offset을 기록하기 위해서 해시 맵 갱신 필요
* 이 방식은 매우 단순해보이지만 실제로 많이 사용하며 비트캐스크(Riak의 기본 저장소)의 근본적인 방식임
  * 비트 캐스크는 해시 맵을 전부 메모리에 유지하 때문에 사용 가능한 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기 쓰기를 보장함.
  * 비트 캐스크 같은 엔진 저장소는 key의 value가 자주 갱신되는 상황에 적합합니다. 
    * key : 고양이 동영상의 url, value : 동영상 클릭 회수
    * 작업부하에 value의 쓰기 작업은 많지만 key는 많지 않은 경우입니다.
#### append-only log에서 디스크 공간
* append-only를 통해서 log를 생성한다면 디스크 공간의 부족이 발생합니다.
* 이를 위한 해결방안은 다음과 같습니다.
  * log가 특정 크기에 도달하면 파일을 세그먼트 단위로 나눕니다.
  * 세그먼트에 compaction을 수행합니다. 
    * compaction이란 log에서 중복된 값을 버리고 키의 최신 업데이트 값만 유지하는 것을 말합니다. 
    * 예를 들어 로그에 click이라는 key에 value가 1, 3, 6, 8, 10라고 순차적으로 기록되었다면 {"click" : 10} 만 남겨 기록하여 크기를 줄입니다. 
  * compaction된 세그먼트 파일을 병합합니다. 
  * 위의 작업들은 백그라운드 스레드를 통해서 수행할 수 있습니다. 
  * 작업을 수행하는 동안 컴팩션하기 전의 파일을 기반으로 동작할 수 있기 때문에 서비스에 중단없이 수행 가능합니다. 
  * redis에서 AOF는 위와 같이 동작합니다. 
* 구현시 고려해야 하는 사항
  * 파일 형식
    * 바이트 단위의 문자열 길이를 부호화한후 원시 문자열을 부호화하는 바이너리 형식이 빠르고 간단
  * 레코드 삭제
    * 키과 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드(tombstone)를 추가해야 함
  * 고장 복구
    * 데이터 베이스가 재시작되면 인메모리 해시 맵은 손실됨
    * 원칙적으로 전체 세그먼트 파일의 full scan해서 각 키에 대한 최신 값을 확인해서 해시맵을 복원 할 수 있습니다. 
    * 너무 큰 세그먼트의 경우 시간이 오래 걸리 수 있기 때문에 빠르게 복구하기 위한 스냅샵을 디스크에 저장해서 복구 속도를 높입니다. 
  * 부분적으로 레코드 쓰기
    * 데이터 베이스가 로그에 레코드를 추가하는 도중에 죽을 수 있기 때문에 손상된 로그를 체크섬을 통해서 무시 할 수 있음
  * 동시성 제어
    * 쓰기 작업의 일반적인 구현은 하나의 쓰레드를 통해서 구현함
    * 읽기 작업은 다중 스레드로 접근이 가능함
* update방식 대신 append-only 로그를 사용하는 이유
  * 추가 및 순차적인 쓰기 작업이라서 무작위 쓰기보다 훨씬 빠름
  * 동시성과 고장 복구가 훨씬 간단합니다. 
    * 예를 들어 로그를 update하다가 죽는 경우에 대한 걱정이 필요 없음
    * append-only의 경우 이전의 기록과 새로운 기록이 모두 남기 때문
  * 오래된 세그먼트 병합은 조각화되는 데이터 파일 문제를 피할 수 잇음
* 해시 테이블 인덱스의 제한사항
  * 해시 테이블을 메모리에 저장해야 하기 때문에 키가 너무 많은 경우 문제가 된다.
    * 디스크에 해시 테이블을 유지관리하게 되면 무작위 접근 I/O 및 디스크 확장 비용등등 다양한 문제 발생
  * 해시 테이블은 범위 질의에 효율적이지 않습니다. 

### SSTable과 LSM 트리
#### SSTable(Sorted String Table)
* 앞에서 설명한 key-value의 세그먼트 파일의 내부 데이터를 key를 기준으로 정렬한 것을 SSTable이라고 부릅니다. 
* SSTable로 병합된 세그먼트에는 각 키가 한번만 나타나야합니다.(compaction 과정 적용)
#### 해시 인덱스에 비해서 SSTable이 가진 장점
* 세그먼트의 병합이 간단하고 효율적입니다. 
  * 순차적으로 정렬되어 있기 때문에 첫번째키부터 순차적으로 동작할 수 있습니다. 
* 파일에서 특정 키를 찾기 위해서 더는 메모리에 모든 키의 색인을 유지할 필요가 없습니다. 
  * 특정 key를 인메모리 인덱스에 찾지 못한다 하여도 SSTale이 정렬되어 있으므로 가장 가까운 값을 찾아서 범위를 scan하면 값을 찾을 수 있습니다. 
    * 이러한 검색을 지원하기 위해서 희소 인덱스가 필요합니다. 
    * 예제) 만약 "H"라는 값을 찾기
      * 희소인덱스 : [A, E, J, M, Q, U]
      * 동작 : E부터 J 구간을 스캔해서 H값을 Find
* 읽기 요청은 요청 범위내에서 여러 key-value를 스캔하기 때문에 해당 레코드를 그룹화하고 압축해서 관리합니다. 
  * 희소 인덱스는 압축된 블록의 시작을 가르킵니다. I/O 대역폭도 이득
#### SSTable 생성과 유지 

    


# 추가로 공부할 내용
## 1