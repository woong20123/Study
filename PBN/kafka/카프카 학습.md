# 서문
### 카프카를 디자인하게 된 이유
* 링크드인에서 내부 인프라 시스템 구축을 위해서 시작됨
* 실시간 어플리케이션과 데이터 흐름을 지원하기 위해서 
* 카프카는 메시지 스트림을 읽게 해주는 메시징 시스템
  * 전통적인 메시징 시스템 : ActiveMQ, RabbitMQ, IBM's MQSeries
### 전통적인 메시징 시스템과 다른 점
1. 카프카는 클러스터로 실행되며 확장 가능한 분산 시스템으로 실행됩니다.
   * 데이터 스트림 처리를 위해 탄력적으로 확장할 수 있음
2. 원하는 충분한 시간동안 데이터를 저장하기 위해 만들어진 스토리지 시스템입니다. 
   * 신뢰성 있는 데이터 전송을 보장, 서로 다른 시스템의 연결 계층으로 사용
3. 대부분의 메시징 시스템은 단순히 메시지 전달만 초점을 가지지만 카프카는 스트림 프로세싱 능력이 있음

# 1장 카프카 흝어 보기
### 메시지 발행과 구독하기(publish/subscribe)
* 메시지 발행/구독 시스템에서는 데이터를 발생자가 직접 구독자에게 보내지 않음
* 대신 발행자가 메시지를 발행/구독 시스템에 전송하면 구독자가 특정 부류의 메시지를 구독할 수 있게됨
* 이때 발생된 메시지를 저장하고 중계하는 역활을 브로커가 수행
## 카프카 살펴보기
* 카프카는 `분산 커밋 로그` 및 `분산 스트리밍 플랫폼`이라고 부름
* DB의 commit 로그와 비슷하게 카프카 데이터에 대해서 지속해서 저장하고 읽을 수 있습니다.
* 시스템 장애와 확장에 따른 성능 저하를 방지하기 위해서 데이터를 분산합니다 .
### 카프카 메시지와 배치
* 카프카의 데이터의 기본단위 메시지이며 바이트 배열로 관리됨 
  * DB의 row와 record와 비교됩니다. 
* 메시지에는 key라는 메타 데이터가 포함 될 수 있음
* 메시지는 topic으로 분류되는 partition에 저장되며 일관된 해시값으로 키를 생성해서 분류됩니다. 
* 카프카는 효율성을 위해서 여러 개의 메시지를 모아서 batch형태로 파티션에 수록함
* 배치 크기가 클수록 단위시간당 처리되는 메시지는 많아지지만 전송시간은 길어집니다. 
* 추가로 배치는 데이터 압축이 되므로 더 효율적으로 동작합니다. 
### 스키마
* 카프카의 메시지는 바이트 배열로 처리되지만 내용의 이해가 쉽도록 스키마를 사용 할 수 있습니다.
* 여러 표준 형식이 있지만 간단한 방식으로 JSON과 XML을 주로 사용합니다. 
* 그러나 강력한 기능을 사용하려면 아파치 Avro를 사용합니다. 
  * 아파치 Avro는 하둡을 위해서 개발된 직렬화 프레임 워크임
* 카프카에서는 일관된 데이터 형식이 중요함
  * 메시지 쓰기 작업가 읽기 작업의 분류 필요
  * 카프카는 잘 정의된 스키마를 공유 리포지토리에 저장해서 사용 할 수 있음
### 토픽과 파티션
* 참조 사이트: https://kafka.apache.org/intro 
* 토픽(topic)은 DB의 테이블이나 FS의 폴더와 비슷함
* 토픽은 여러개의 파티션으로 구성될 수 있으며 메시지는 파티션에 끝에 추가됨
* 각 파티션은 서로 다른 서버에 분산 적재 될 수 있음(I/O 분산을 통한 성능 향상)
  * 수평적 확장 가능
* 카프카에서 스트림이란 프로듀서(producer)로 부터 컨슈머(consumer)로 이동되는 연속적인 데이터를 말함
### 프로듀서와 컨슈머(생산자와 소비자)
* 카프카의 클라이언트는 시스템의 사용자이며 프로듀서나 컨슈머라는 두가지 형태를 지닙니다. 
* 프로듀서는 새로운 메시지를 생성하며 발행자/작성자라고 합니다.
  * 프로듀서는 특정 토픽을 대상으로 메시지를 생성하며 어떤 파티션에 수록되는지 관여하지 않습니다. 
  * 특수하게 파티션을 지정할 때는 메시지 키를 사용합니다. 
* 컨슈머는 메시지를 읽으며 다른 발행/구독 시스템에서 구독자/독자라고 합니다. 
* 컨슈머는 메시지가 생성된 순서대로 읽으며 오프셋을 유지함 
  * 오프셋은 지속적으로 증가하는 정수값입니다. 
  * 주키퍼나 카프카에서는 각 파티션에서 마지막에 읽은 메시지의 오프셋을 저장하므로 메시지 읽기를 중단하더라도 그 다음 메시지를 읽을 수 있음
* 컨슈머는 컨슈머 그룹의 멤버로 동작합니다. 
* 컨슈머 그룹은 하나의 토픽을 소비하기 위해서 같은 그룹의 여러 컨슈머화 함께 동작합니다. 
* 한 토픽의 각 파티션은 하나의 컨슈머만 소비할 수 있습니다. 
  * 이처럼 컨슈머가 특정 파티션에 대응 되는 것을 파티션 소유권이라고 합니다. 
  * 이방식을 사용하면 대량의 메시지를 갖는 토픽을 수평적으로 확장합니다.
  * 만약에 컨슈머가 자신의 파티션의 메시지를 읽는 데 실패하더라도 같은 그룹의 다른 컨슈머가 파티션 소유권을 재조정 받아 처리 할 수 있음
### 브로커와 클러스터 
* 하나의 카프카 서버를 브로커(broker)라고 합니다.
* 브로커는 프로듀서로 부터 메시지를 수신하고 오프셋 지정후 저장
* 컨슈머의 파티션 읽기 요청에 응답하고 디스크의 메시지를 전송
  * 일반적으로 하나의 브로커는 초당 수천 개의 토픽과 수백만개의 메시지를 처리합니다. 
* 카프카의 브로커는 클러스터의 일부로 동작함 
  * 여러개의 브로커가 하나의 클러스터에 포함될 수 있으며 그중에 하나는 자동으로 선정되는 클러스터 컨트롤러의 기능을 수행
* 클러스터 컨트롤러는 각 브로커에게 담당 파티션을 할당하고 모니터링 기능 수행 
* 각 파티션은 클러스터의 한 브로커가 담당하며 파티션 리더라고 부르며 파티션은 여러 브로커에 복제될 수 있습니다. 
* 각 파티션을 사용하는 모든 컨슈머와 프로듀서는 파티션 리더와 연결되어야 합니다. 
* 아파치 카프카의 핵심 기능 보존 기능
  * 카프카는 기본적으로 토픽의 보존 설정을 할 수 있습니다.
    * 예를 들어 7일과 같이 메시지를 보존하거나 1GB와 같이 지정된 크기가 될때까지 메시지를 보존함
### 다중 클러스터
* 카프카의 복제 메커니즘은 단일 클러스터에만 동작하도록 설계
* 다중 클러스터의 복제를 위해서는 미러메이커라는 도구를 사용해야 함

## 카프카를 사용해야 하는 이유
### 다중 프로듀서
* 카프카는 무리없이 많은 프로듀서의 메시지를 처리할 수 있음
### 다중 컨슈머
* 다중 프로듀서와 더불어 많은 컨슈머가 상호 간섭없이 어떤 메시지도 읽을 수 있도록 지원
* 큐 시스템과는 다르게 이미 소비한 메시지를 다른 클라이언트와 공유 할 수 있음
### 디스크 기반 보존
* 카프카는 지속해서 메시지를 보존할 수 있음
* 컨슈머 애플리케이션이 항상 실시간으로 실행되지 않아도 됨
* 컨슈머가 다시 실행되면 중단 시점의 메시지부터 처리 가능
### 확장성 및 고성능 지원
## 데이터 생태계
### 이용 사례
#### 활동 추적
* 링크드인에서 프런트엔드에서 사용자의 행동 패턴을 수집해서 카프카에 전송하면 백엔드에서 소비하는 형태
#### 메시지 전송
* 알림 메시지를 전송해야하는 애플리케이션에 유용함
#### 메트릭과 로깅
* 애플리케이션의 메트릭과 로그 데이터를 모으는데 이상적
  * 메트릭이란 타임스탬프와 숫자값을 포함하는 이벤트, 주기적인 발생
#### 커밋 로그
* DB의 변경사항을 카프카 메시지 스트림으로 생성할 수 있음
#### 스트림 프로세싱
* 메시지가 생성되자마자 실시간으로 데이터 처리가능 

## 카프카의 기원
* 카프카는 링크드인의 파이프라인의 문제를 해결을 위해 고성능 메시징 시스템을 제공하도록 개발됨
* 다양한 유형의 데이터 처리 및 실시간 제공을 위한 메시징 시스템

### 링크드인의 문제점
* 시스템과 애플리케이션의 매트릭을 집중하는 것 
* 사용자 활동 정보를 추적하기 위한 HTTP 서비스 
* 장애 사항
  * 일관된 규칙이 없어서 많은 시간 및 노력 소요
  * 시스템이 다르면 일관성이 깨짐 
### 카프카의 탄생
* 주된 요구사항
  * push-pull 모델을 사용해서 메시지 프로듀서와 컨슈머를 분리시킨다. 
  * 다수의 컨슈머가 사용할 수 있게 메시징 시스템의 데이터를 지속적으로 보존한다. 
  * 많은 메시지 처리량에 최적화시킨다.
  * 수평확장을 지원한다. 
* 카프카의 확장성 덕분에 매일 1조개 이상이 생성되고 1페타바이트의 데이터를 소비되는 사이트로 성장

# 2장 카프카 설치와 구성하기 
### 운영체제 선택하기  
* 카프카는 다양한 운영체제에 설치 가능합니다. 
* 책에서는 리눅스에 카프카를 설치하고 사용하는 데 초점을 둡니다. 

### 리눅스 설치 
vmware를 통해서 ubuntu 18.4 설치

### 자바 설치하기 
* JDK 11 버전 설치 
```
sudo apt-get install openjdk-11-jdk
```
### 주키퍼 설치하기 
* 컨슈머 클라이언트와 카프카 클러스터에 대한 메타 데이터를 저장하기 위해서 사용한다.
```json
sudo apt-get install zookeeper
// zookeeper 실행하기 
/usr/share/zookeeper/bin/zkServer.sh start
ps -ef | grep zookeeper 
// 접속 테스트 하기 
telnet localhost 2181
```

### 주키퍼 앙상블
* zookeeper는 카프카와 같은 분산 처리 시스템의 서버들에 관한 메타데이터를 통합 관리하는데 사용됩니다.
* zookeeper의 클러스터를 앙상블이라고 하며 하나의 앙상블은 여러 개의 서버(node)를 멤버로 가집니다.
* 하나의 서버에만 서비스가 집중되지 않도록 하며 리더 & 팔로워 구조로 구성됩니다.
* 앙상블은 홀수로 지정되며(3개, 5개) 과반수 이상이 작동중이라면 문제 없이 동작합니다. 
  * 3개로 구성되면 2대이상만 정상 작동하면 문제없음, 5개로 구성되면 3대 이상이상만 동작하면 이상없음
  * 일반적으로는 5개의 노드를 가지는 것이 권장

### 카프카 브로커 설치하기
```java
wget http://apache.mirror.cdnetworks.com/kafka/2.6.0/kafka_2.13-2.6.0.tgz
tar -xvf kafka_2.13-2.6.0.tgz
mv kafka_2.13-2.6.0 /usr/local/kafka
// zookeeper 실행
 /usr/local/kafka/bin/zookeeper-server-start.sh -daemon /usr/local/kafka/config/zookeeper.properties

// 카프카 서버 실행
/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties 
```
#### 카프카 토픽 생성하기
* 빠른 시작 Document : https://kafka.apache.org/documentation/#quickstart
```java
// topic 만들기
./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
// topic에 데이터 쓰기
./kafka-console-producer.sh --broker-list localhost:9092 --topic test

// topic에서 메시지 읽기
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
// Ctrl + C 중단
```

### 브로커 구성 설정하기
#### 핵심 구성 요소 
* 설정파일 위치 : /usr/local/kafka/config/server.properties
* Document 경로 : https://kafka.apache.org/documentation/#brokerconfigs
  
|옵션이름| 설 명 |
|:--|:--|
|broker.id|정수로 된 번호. 기본값은 0<br> 카프카 클러스터 내에서 고유한 식별 ID|
|listeners|접속하려는 IP 주소 및 포트 정보|
|zookeeper.connect|브로커의 메타데이터를 저장하기 위한 zookeeper 정보 <br>기본값은 localhost:2181<br> <호스트이름>:<포트>/<경로>로 구성됩니다.<br>카프카 클러스터의 chroot 환경에서 사용될 chroot 경로를 사용할수 있음|
|log.dirs|카프카는 모든 메시지를 로그 세그먼트 파일에 모아서 디스크에 저장함<br> 해당 파일을 저장할 디렉토리 지정<br>기본값 /tmp/kafka-logs|
|num.recovery.threads.per.data.dir|로그 세그먼트를 처리하기 위한 스레드풀의 갯수<br>기본값은 1임<br>해당 스레드는 브로커의 시작과 종료시에 사용되므로 여러 스레드를 설정해도 됨<br>log.dirs의 지정된 경로 마다 해당 갯수만큼 스레드가 생성됨|
#### 토픽의 기본 설정
|옵션이름|설 명|
|:--|:--|
|num.partitions|새로운 토픽이 몇개의 파티션으로 생성되는지 나타냄<br>기본값은 1.<br>파티션의 개수는 증가만 가능함 |
|log.retention.hour|메시지를 보존하는 시간 지정<br>기본값 168시간 = 1주일<br>지정된 시간이 지나면 메시지가 삭제될 수 있다는 뜻이며<br>마지막 수정시간을 기준으로 함|
|log.retention.bytes|저장된 메시지들의 전체 크기를 기준으로 만료 처리<br>기본값은 1 기비바이트<br>파티션당으로 적용되며 모든 파티션에 적용됨|
|log.segment.byte|로그 세그먼트가 지정된 크기가 되면 파일이 닫히고 새로운 것이 되어서 생성됨|
|log.segment.ms|로그 세그먼트가 지정된 시간이 되면 파일이 닫히고 새로운 것이 되어서 생성됨|
|message.max.bytes|메시지의 최대 크길을 제한 할 수 있음<br>기본값은 1MB.<br>메시지의 크기는 압축된 값으로 측정<br>해당 값을 늘리면 즉 메시지가 커지면 메시지당 작업시간이 길어지며 디스크 쓰기 크기가 증가함|


* 파티션 개수의 산정 방법
  * 단위 시간단 토픽의 처리량 
  * 한 파티션의 데이터를 읽을 때 목표로 하는 최대 처리량
    * 파티션 하나는 항상 하나의 컨슈머가 소비함
    * 만약 처리속도가 느린 컨슈머가 초당 50mb를 처리한다면 파티션당 처리량은 초당 50mb
  * 하나의 파티션에 데이터를 생성하는 프로듀서당 최대 처리량
    * 일반적으로 프로듀서의 생산속도는 컨슈머보다 빠르기 때문에 무시해도 됨
  * 키를 사용해서 파티션에 메시지를 쓰는 경우에는 향후 파티션을 추가할 때 갯수 산정이 어려울 수 있음
  * 브로커마다 파티션 갯수와 디스크 용량 및 네트워크 처리 속도를 고려하자.
  * 위의 정보를 기준으로 설명하면 목표 처리량을 컨슈머의 예상 처리량으로 나누는 방법으로 파티션 갯수를 나눠야 합니다 
    * 예를 들어 초당 1GB로 토픽을 읽고 쓰기를 원하는데 각 컨슈머당 초당 50MB를 처리한다면 최소한 20개의 파티션(50MB X 20 = 1GB)이 필요함

### 하드웨어 선택 방법
#### 디스크 처리량
* 브로커의 디스크 처리량은 프로듀서 클라이언트 성능과 연관이 있음
  * 카프카의 메시지가 생성될 때 서버의 스토리지에 커밋되며 커밋 완료 될 때까지 프로듀서 클라이언트 대기함
#### 디스크 용량 
* 디스크 용량은 일정 기간에 얼마나 많은 메시지가 저장되어야 하는지를 기반으로 만들어야합니다. 
* 예를 들어 하루 1TB데이터를 받고 일주일간 저장 보존한다면 최소 7TB 용량이 필요함
  * 추가적으로 10% 버퍼를 두는 것이 좋음
#### 메모리
* 컨슈머가 읽는 파티션의 메시지는 메모리의 페이지 캐시에 최적화됨
* 메모리가 더 많을 수록 컨슈머 클라이언트의 성능이 좋아짐 
#### 네트워크
* 네트워크 처리량은 카프카가 처리 할 수 있는 통신의 트래픽 최대량을 나타냄
* 프로듀서는 하나의 토픽에 접근하지만 토픽의 컨슈머는 다수가 될 수 있으므로 아웃바운드 네트워크 사용량이 많아 질 수 있음
#### CPU
* CPU는 디스크와 메모리보다 덜 중요함
* 네트워크과 디스크의 사용을 최적화 하기 위해서 메시지를 압축해서 전송 할 수 있음
* 카프카 브로커는 각 메시지의 체크섬을 검사하고 오프셋을 지정하기 위해서 모든 메시지의 압축을 풀어야 함
  
### 카프카 클러스터
* 다수의 브로커의 장점
  * 처리량을 분산 시켜 확장 할 수 있음
  * 서버 장애에 대비해서 복제 할 수 있음 
#### 브로커의 갯수 
* 메시지 보존을 기반
  * 10TB 데이터를 보존 해야 하고, 하나의 브로커가 2TB까지 사용 가능 하다면 최소 5개의 브로커가 필요
  * 추가로 복제를 한다면 최소 10개의 브로커가 필요함
* 요청 처리량을 기반
  * 만약에 특정 시간에 컨슈머 하나가 네트워크 인터페이스의 80%를 점유한다면 컨슈머가 2개인 경우 브로커도 2개이어야 함
#### 브로커 구성 
* 모든 브로커의 zookeeper.connect 설정 값이 같아야 합니다. 
* broker.id는 고유 값을 가지도록 설정해야 합니다.
#### 운영체제 조절
* 가상메모리, 네트워크 서브 시스템, 디스크 마운트 
  * 대다수는 /etc/sysctl.conf를 통해서 조절 할 수 있음
* 가상 메모리
  * 카프카에서 스왑이 발생하는 것을 방지하기 위한 작업 필요
  * vm.swappiness 매개변수 값을 1로 설정  = 이 값은 %를 표현함
  * vm.dirty_background_ratio 10보다 적게 설정
    * 백그라운드 스레드가 디스크에 써야하는 더티 페이지 비율 조절
  * vm.dirty_ratio 기본값 20에서 60 ~ 80으로
    * 더티 페이지의 전체 분량
* 디스크 
  * XFS 파일시스템 권장
  * 마운트 옵션은 noatime으로 설정하는 것이 좋음
    * noatime을 설정하면 atime(마지막 사용시간)을 기록하지 않음 
* 네트워크 
  * 리눅스 커널은 대용량의 초고속 데이터 전송에 맞도록 조정되지 않았음 = 수정 필요
  * 각 소켓의 송수신 버퍼로 할당되는 기본과 최대 메모리량을 변경하기
    * net.core.wmem_default : 131072
    * net.core.rmem_default : 131072
    * net.core.wmem_max : 2097152(2MiB)
    * net.core.rmem_max : 2097152(2MiB)
    * net.ipv4.tcp_wmem : 최소 기본 최대
    * net.ipv4.tcp_rmem : 최소 기본 최대
    * net.ipv4.tcp_window_scaling : 1
    * net.tcp_max_syn_backlog를 1024보다 크게하면 훨씬 많은 동시 연결 허용
    * net.core.netdev_max_backlog의 기본값인 1000보다 크게 설정하면 커널이 더 많은 패킷을 처리할 수 있습니다. 

## 업무 사용시 고려 사항
### 가비지 컬렉션 옵션 
* 자바 7부터 G1이라는 가비지 컬렉터가 추가됨
* G1에 대한 성능 조정 구성 옵션
  * MaxGCPauseMillis
    * 가비지 컬렉션 작업의 중지 시간
  * InitiationHeapOccupancyPercent
    * 사용 중인 전체 힙의 비율 지정 

# 카프카 프로듀서 : 카프카에 메시지 쓰기
* https://www.confluent.io/blog/apache-kafka-spring-boot-application/?utm_medium=sem&utm_source=google&utm_campaign=ch.sem_br.nonbrand_tp.prs_tgt.kafka_mt.mbm_rgn.apac_lng.eng_dv.all&utm_term=%2Bkafka%20%2Bspring&creative=&device=c&placement=&gclid=CjwKCAjwq_D7BRADEiwAVMDdHu9rOxjVgRzlVqwuB5xr0uEsthvuSbGvjRTWyJ_72gYIJZ1xnqKPPBoCOMwQAvD_BwE#one
## 프로듀서 개요
* 카프카를 사용하는 이유는 다양하며 그렇기 때문에 요구 사항도 다양하다.
  * 예를 들어서 신용카드 트랜잭션은 메시지가 유실되지 않으며 복제가 되면 안되고 처리 대기 시간은 500밀리초안에 처리되어야 함
#### 프로듀서 API 내부 동작 방식 
* 카프카에 쓰려는 메시지를 가지는 ProducerRecord를 생성함
  * ProducerRecord 구조
    * 토픽
    * 파티션
    * 키
    * 값
* ProducerRecord를 serializer 클래스를 통해서 직렬화 함
* ProducerRecord를 파티셔너 클래스를 통해서 전달 
  * 키를 기준으로 파티션 처리 됨
* 메시지 전송처리

## Java에 kafka 프로듀서 설정하기 
```java
private Properties kafkaProps = new Properties();
```
## Spring에 kafka 프로듀서 설정하기 
#### [설정파일 doc 링크](http://kafka.apache.org/documentation.html#producerconfigs)
#### 프로듀서 설정 파일 설명
|설정|내용|
|:--|:--:|
|bootstrap.servers|카프카 클러스터에 최초로 연결하기 위해서 <br>프로듀서가 사용하는 브로커 목록<br>모든 브로커를 등록할 필요는 없지만<br>장애 대응을 위해서 최소한 2개 이상 등록 권장|
|key.serializer|프로듀서가 생성하는 레코드의 메시지 키를 직렬화하기 위해서 사용되는 클래스<br> org.apache.kafka.common.serialization.Serializer 인터페이스 구현 필요<br>카프카 클라이언트 패키지에는 ByteArraySerializer, StringSerializer, IntegerSerializer 포함 |
|value.serializer|레코드의 메시지 값을 직렬화 하는데 사용되는 클래스 |
|acks|전송된 레코드를 수신하는 파티션 리플리카의 수를 제어한다 <br>0일때는 프로듀서는 브로커의 응답을 기다리지 않음<br>1일때 리더 리플리카가 메시지를 받는 순간 수신 응답<br>all일때 동기화된 모든 리플리카가 메시지를 받으면 성공 응답. 안정하지만 가장 느림|
|buffer.memory|브로커들에게 전송될 메시지의 버퍼로 사용할 메모리량 설정<br>너무 빠른 속도록 애플리케이션에 전송된다면 버퍼 메모리가 부족할 수 있음|
|compression.type|메시지는 기본적으로 압축되지 않은 상태로 전송됨<br>이 값을 snappy,gzip, lz4중 하나로 설정하면 압축알고리즘 적용됨<br>snappy 알고리즘 구글에서 만듬 성능 좋음|
|retries|메시지의 재전송 회수를 셋팅합니다.|
|batch.size|같은 파티션에 쓰는 레코드가 전송 될 때 배치로 모아서 전송|
|linger.ms|배치를 전송하기 전에 기다리는 시간 설정.<br>배치가 가득차거나 해당 시간이 경과되면 전송한다.|
|client.id|전송메시지가 누구한테 생성되었는지 확인 하기 위한 identity값|
|max.in.flight.requests.per.connection|서버의 응답을 받지 않고 전송하는 메시지의 갯수|
|max.request.size|전송 될 수 있는 메시지의 크기를 제어합니다. <br>기본값은 1MB이며 프로듀서는 1KB 크기의 메시지를 최대 1024개 전송 할 수 있습니다.|

### 메시지 순서 보장하기 
* 일반적으로 카프카는 파티션 내부의 메시지 순서를 유지함
* 하지만 재전송으로 인해서 순서가 뒤바뀌는 경우 발생
  * retries 값이 0이 아니고 max.in.flight.requests.per.connection 매개변수를 1보다 크게 설정한 경우
* 일반적으로 신뢰성이 중요하다면 retries 값을 0이 아닌 값을 설정하지 않습니다. 
* 순서를 유지하는 것이 중요하다면 in.flight.requests.per.session을 1로 설정하는 것을 권장함

#### spring boot에서 producer 설정파일 셋팅
```ini
spring.kafka.consumer.bootstrap-servers=172.19.138.12:9092
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.group-id=foo
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

spring.kafka.producer.bootstrap-servers=172.19.138.12:9092
spring.kafka.producer.key-serializer.=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
```

### 메시지 전송방법
#### Fire-and-forget(전송후 망각)
* 간단한 방법으로 send()로 메시지만 전송 실패여부 확인 하지 않음
* 대부분은 프로듀서가 자동으로 재전송 시도함 
* 하지만 이방법은 일부 메시지가 유실 될 수 있음
#### Synchronous send(동기전송)
* send()메서드로 메시지 전송시 자바의 Future 객체 반환 
* Future객체의 get메서드를 통해서 작업 완료 대기
#### Asynchronous send(동기전송)
* send() 메서드 호출시 콜백 메서드 구현 

## kafka 설정 파일 셋팅
* kafka broker의 server.properties 파일의 listeners의 주소를 외부 주소로 설정한다.
```ini
listeners=PLAINTEXT://172.19.138.12:9092
```

```curl
curl -d "key1=value1&key2=value2" -X POST http://localhost:8080/data
```

## 직렬 처리기
* 커스텀해서 만들 수 잇음
* 아파치 Avro를 사용할 수 잇음
  * 장점은 스키마 변경에 대해서 에러 없이 사용 할 수 잇음

## 파티션 
* ProducerRecord 객체는 토픽 이름과 키, 값을 포함
* 만약에 키가 없이 토픽과 값만 전송되면 키는 null이 되고 라운드 로빈 방식으로 각 파티션에 저장됩니다. 
* 키가 있다면 기본 파티셔너를 사용하면 해시 값을 구해서 특정 파티션에 저장합니다. 

# 카프카 컨슈머 
## 컨슈머의 중요 개념
### 컨슈머와 컨슈머 그룹
* 어떤 토픽을 소비하는 컨슈머가 있는데 만약 프로듀서의 생산속도를 따라 잡지 못한다면 어떻게 진행되어야 하는가?
  * 메세지가 계속 누적되서 처리속도가 느려진다.
  * 컨슈머를 추가해서 분담해야한다. 
* 이렇게 묶인 컨슈머들을 컨슈머 그룹이라고 말합니다. 
* 같은 컨슈머의 그룹들은 서로 다른 파티션을 분담해서 메시지를 처리합니다. 
* 토픽의 파티션보다 더 큰수의 컨슈머를 추가하는 것은 의미가 없습니다. 
* 새로운 컨슈머 그룹이 추가되면 모든 토픽의 메시지를 읽습니다. 
### 컨슈머 그룹과 리밸런싱
* 컨슈머 그룹은 컨슈머들이 읽는 토픽의 파티션 소유권을 공유함
* 컨슈머끼리 파티션의 소유권을 이전하는 것을 리밸런싱이라고 부릅니다. 
* 리밸런싱이 발생하는 동안 메시지를 읽을 수 없습니다.
* 이전될때는 컨슈머의 이전 파티션에 대한 상태 정보는 사라짐
* 그룹 지정자로 지정된 브로커에게 컨슈머가 하트비트를 전송하면 컨슈머 그룹의 멤버쉽과 파티션 소유권을 유지함 
* 하트비트는 컨슈머가 폴링이나 커밋할때 자동 전송
* 만약 일정기간동안 하트 비트가 전송되지 않는다면 리밸런싱 시작

### Spring Boot kafka
* https://docs.spring.io/spring-kafka/reference/html/#message-listeners
#### 컨슈머 구성하기 
|설정|내용|
|:--|:--:|
|fetch.min.bytes||
