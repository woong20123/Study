## 아파치 스파크란?
* 통합 컴퓨팅 엔진이며 클러스터 환경에서 데이터를 병렬로 처리하는 라이브러리 집합
* 개발자와 데이터 과학자에게 표준도구가 되고 있음
* 파이썬, 자바, 스칼라, R을 지원하며 SQL, 스트리밍, 머신러닝 지원
* 스파크는 단일 노트북에서 수천대의 서버 구성의 클러스터까지 다양한 환경에서 실행가능

## 아파치 스파크의 철학
### 통합
* 스파크의 핵심 목표는 빅 데이터 애플리케이션 개발에 필요한 통합 플랫폼을 제공하자
* 스파크 API는 사용자 애플리케이션에서 다른 라이브러리의 기능을 조합해서 더 나은 성능을 발휘할 수 있음
  * 예를 들어 SQL쿼리로 데이터를 읽고 ML라이브러리로 머신러닝을 진행할때 스파크 엔진을 두단계를 병합해줍니다. 
### 컴퓨팅 엔진
* 스파크는 저장소 시스템의 데이터를 연산하는 역활만 수행하고 데이터를 저장하지 않습니다. 
  * 대신에 애저 스토리지, 아마존 S3, 아파치 하둡, 카산드라, 카프카등의 저장소를 지원합니다. 
* 스파크는 데이터 저장위치에 상관없이 처리에 집중합니다. 
### 라이브러리
* 스파크의 컨포넌트는 데이터 분석 작업에 필요한 통합 API를 제공하는 통합 엔진 기반의 자체 라이브러리 입니다. 
* 스파크의 표준라이브러리들은 여러 오픈소스 프로젝트의 집합체입니다. 

## 스파크의 등장 배경
* 데이터 수집 비용은 아주 저렴해지면서 데이터를 클러스터에서 처리될 정도로 커짐
* 프로세서의 성능은 한계로 인해서 병렬 프로세서의 시대로 변경됨 

## 스파크의 기본 아키텍쳐
* 스파크 애플리케이션은 드라이버 프로세스와 익스큐터 프로세스로 구성됨
* `드라이버` 프로세스는 유지관리, 입력에 대한 응답, 익스큐터 작업등등 스파크의 전반적인 관리작업을 수행합니다. 
* `익스큐터`는 드라이버 프로세스가 할당한 작업을 수행합니다. 
* 클러스터 매니져는 물리적 머신을 관리합니다. 

## 스파크의 다양한 언어 API
* 스칼라
  * 스파크는 스칼라로 개발되어 있음
  * 스파크의 기본언어임
* 자바
  * 스파크는 스칼라로 개발되어 있지만 자바를 이용해서 스파크를 지원할 수 있도록 심혈을 기울입니다. 
* 파이썬
  * 스칼라가 지원하는 거의 모든 구조를 지원함
* SQL
  * ANSI SQL:2003 표준중에 일부를 지원합니다. 
* R
  * SparkR과 커뮤니티 기반의 sparklyr을 지원합니다. 

## 스파크 시작하기 
### 예제를 통해서 sparkSession에 접속해서 1000개의 숫자를 나열하는 데이터 프레임을 생성합니다. 
```java
spark_shell

// 스파크 세션 연결
scala> spark

scala> myRange = spark.range(1000).toDF("number")

scala> myRange.show()
```
### DataFrame
* DataFrame은 테이블의 로우와 컬럼을 단순하게 표현합니다. 
* 스파크의 DataFrame은 수천 대의 컴퓨터에 분산되어 저장되어 있습니다.
  * 파이썬이나 R에서도 DataFrame이 있지만 단일 컴퓨터에 저장되어 있습니다. 

### 파티션
* 스파크는 모든 익스큐터가 병렬로 작업을 수행할 수 있도록 파티션이라고 불리우는 청크 단위로 데이터를 분할합니다. 
* 파티션이란 클러스터의 물리적 머신에 존재하는 row의 집합입니다. 
* DataFrame을 사용하면 스파크가 파티션을 결정해서 적용합니다. 
  
## 트랜스포메이션
* 스파크의 핵심 데이터 구조는 불변성(immutable)을 가집니다.
* 만약에 DataFrame을 변경하려면 스파크에 알려야 합니다. 
* 이때 알리는 방법을 트랜스포메이션이라고 합니다.
```scala
val divisBy2 = myRange.where("number % 2 = 0")
```
* 위의 코드만 수행하면 실제 트랜스포메이션을 실행하지 않습니다. 실제 액션시 수행됩니다. 
### 좁은 의존성
* 좁은 의존성을 가진 트랜스포메이션은 각 입력 파티션이 하나의 출력파티션에만 영향을 미칩니다. 
* 이 경우에는 스파크에서 파이프라이닝을 자동으로 수행합니다.
### 넓은 의존성
* 넓은 의존성을 가진 트랜스포메이션은 하나의 입력 파티션이 여러 출력 파티션에 영향을 미칩니다. 
* 셔플을 사용하면 셔플의 결과를 디스크에 저장합니다. 

### 지연 연산
* 지연 연산이란 스파크가 연산 그래프를 처리하기 직전까지 기다리는 동작 방식을 의미함
* 실제로 연산 명령이 내려지면 스파크는 `실행계획`을 생성함
* 실제로 연산시에는 원형 DataFrame 트랜스포메이션을 간결한 물리적 실행 계획으로 컴파일합니다.

### 액션
* 실행 계획을 실제 수행하기 위해서는 액션 명령이 있어야 합니다.
* 가장 단순한 액션인 count 메서드는 전체 레코드수를 반환합니다. 
* 액션의 종류
  * 콘솔에서 데이터를 보는 액션
  * 각 언어로 된 네이티브 객체에 데이터를 모으는 액션
  * 출력 데이터소스에 저장하는 액션 
* 액션을 수행하면 스파크 잡이 시작되고 필터(좁은 트랜스포메이션)를 수행한 후 레코드 수를 카운트 합니다. 
