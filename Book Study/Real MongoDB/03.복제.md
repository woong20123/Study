## 복제(Replication)란 무엇인가?
* 여러 서버가 서로의 데이터를 동기화하는 것을 의미합니다. 
  
### 컨센서스(Consensus Algorithm) 알고리즘
* 레플리카 셋이란 서로 데이터를 같이 공유하는 그룹을 뜻합니다.
  * 프라이머리, 세컨더리로 각자의 역활을 나누어서 관리합니다. 
* 레플리카 셋에서 각 서버들이 작동하는 방식을 `컨센서스 알고리즘`이라고 부릅니다.
  * MongoDB는 확장된 형태의 `Raft 컨센서스 모델`을 사용합니다.
    * Paxos 컨센서스 모델은 아무 멤버나 데이터를 수정 가능함
    * Raft 컨센서스 모델은 특정 멤버가 데이터 수정 가능함 
  * MongoDB는 리더 기반 복제로 동작하며 팔로워들이 리더의 로그를 가져와서 동기화를 수행합니다. 
  
### 복제의 목적
* 복제의 목적은 고가용성을 위한 중복된 데이터 셋을 준비하는 것입니다.
* 레플리카 셋의 내부의 서버들은 서로간의 통신(하트비트)을 통해서 고가용성을 유지합니다.
  * primary의 통신이 두절되면 새로운 primary를 선출합니다
* 세컨더리 멤버가 늘어나면 늘어난 수 만큼 Read 작업을 분산할 수 있습니다. 
* MongoDB 서버의 경우 서비스 도중 물리적 백업 기능을 제공하지 않음
  * mongoexport를 통해서 논리적 백업은 제공 - 복구 시간이 오래걸림
  * 일시적으로 세컨더리를 멈추고 데이터 파일을 복사로 처리
  * 파일 시스템 스냅샷 - 리눅스 LVM
  * Percona 온라인 백업

## 레플리카 셋 멤버
* 레플리카 셋에는 최대 50개의 멤버가 참여할 수 있고 7개까지 멤버 선출에 참여 할 수 있음'
  * 너무 많은 멤버는 유지관리 비용(하트비트)이 많이 듬

### 프라이머리(Primary)
* 레플리카 셋에서 데이터 변경을 처리하는 유일한 멤버
  
### 세컨더리(Secondary)
* 프라이머리에서 변경된 데이터를 실시간으로 가져와서 프라이머리와 동일한 데이터 셋을 유지합니다.
* 세컨더리가 프라이머리로 역활이 변경되는 것을 프로모션 또는 스텝-업이라고 합니다. 
* 데이터 읽기 요청이 처리될 수 있기 때문에 읽기 작업에 대한 분산 용도로 사용할 수 있습니다. 
  
### 아비터(Arbiter)
* 아비터는 레플리카 셋의 멤버로 참여해서 프라이머리 선출에만 참여하며 데이터를 가지지 않습니다. 
* Quorum을 채우기 위한 추가 멤버가 필요한 경우 아비터를 사용합니다. 

## 프라이머리 선출 
### 프라이머리 텀(Primary Term)
* 프라이머리 텀은 투표 식별자로 불리며 투표 요청에 대한 논리적인 시간 값을 기록합니다.
  * 프라이머리 텀은 3.2버전에서 업데이트 되었으며 그전에 식별자가 없었기 때문에 30초라는 정적인 시간을 기준으로 텀을 사용했습니다. 
* OpLog 기록시 프라이머리 텀을 사용해서 로그 기록이 어느 시점에 남았는지 추적합니다. 

### 프라이머리 스텝 다운(step down)
* 스텝 다운을 통해서 강제적으로 primary를 secondary로 내리는 것도 가능합니다. 
* 스텝 다운 방법
  * rs.stepDown() 명령
  * rs.reconfig()으로 레플리카셋 멤버의 우선순위 변경
```js
// stepDownSecs : 지정된 시간동안 프라이머리로 선출될 수 없도록 지정합니다.
// secondaryCatchUpPeriodSecs : 밀려 있던 복제 동기화 작업이 완료되길 기다립니다. 
//                              만약 동기화가 빨리 완료되면 바로 StepDown 작업을 수행합니다.
rs.stepDown(stepDownSecs, secondaryCatchUpPeriodSecs)
```

### 프라이머리 선출 시나리오
* `Self-Election` 방식을 통해서 선출합니다. 
  * 기본적인 요건만 채워지면 자기 자신을 프라이머리로 선출 합니다.
  * 선출 요청이 오면 아래의 체크 사항을 확인합니다.
    * 선출되는 프라이머리가 같은 레플리카 셋에 소속되어 있는가??
    * 우선순위가 같거나 큰 값을 가지고 있는가?
    * 요청한 Term이 정상적인가?
    * 요청한 세컨더리가 나보다 최신 데이터를 가지고 있는가?
  
### 롤백
* mongo에서 `롤백`이란 레플리카 셋에서 멤버끼리 서로 동기화 하는 과정에서 이미 저장된 데이터를 다시 삭제하는 과정을 말합니다. 
* 발생할 수 있는 예제
  * 레플리카 셋에서 Oplog를 복제하기 전에 primary에서 장애 발생함
  * 세컨더리들은 완벽하지 않은 데이터를 들고 있는 상태에서 데이터가 쌓임
  * 장애가 발생한 이전의 primary 장비가 살아나면 현재 primary와 데이터 검증을 통해서 롤백으로 데이터 복구
* 롤백으로 인한 데이터 복구는 300MB까지 가능함
* 자동 롤백이 실패한 경우 rollback 디렉토리에 기록되지 않으므로 데이터 파일을 백업해야 합니다. 
```js
<database>.<collection>.<timestamp>.bson
예제) mydb.mycoll.2016-10-30T20-02-00.0.bson

bsondump mydb.mycoll.2016-10-30T20-02-00.0.bson > rollback_mycoll.json

mongorestore --db mydb --collection mycoll --file ./rollback_mycoll.json
```
  
## 복제 아키텍쳐
* 복제는 프라이머리의 OpLog를 복제 할 수도 있지만 세컨더리의 Oplog도 복제할 수 있습니다. 
* MongoDB는 `oplog.rs`라는 이름의 테이블로 기록하며 아래의 필드를 가집니다. 
  * ts : 이 필드는 OpLog의 저장 순서를 결정하는 기준입니다. 
  * t(Primary Term) : Timestamp와 같이 증가하는 값
  * h : 데이터 변경작업에 부여되는 해시 값 
  * v : Oplog의 도큐먼트 버전을 의미하여 기본적으오 2를 가짐
  * op : 프라이머리에서 실행된 오퍼레이션 종류를 기록합니다. i(insert), d(Delete), u(Update), c(Command), n(No Operation)
  * ns : 데이터가 변경된 대상 컬렉의 네임스페이스가 저장됨. `db_name$cmd`
  * o : op필드에 저장된 오퍼레이션 타입별로 실제 변경된 정보가 저장됨(변경된 값 저장)

### Local 데이터 베이스
* 복제 로그는 oplog.rs라는 컬렉션을 통해서 세컨더리 멤버로 전달됩니다. 
* mongo는 oplog.rs와 몇 개의 테이블을 local 데이터 베이스에 저장합니다. 
* local 데이터 베이스의 변경작업은 oplog.rs에 기록되지 않습니다. 
  * 모니터링이나 백업과 같은 관리 데이터를 저장하면 복제가 발생하지 않음
  * Cap 컬렉션으로 사용하는 것 좋습니다.

### 초기 동기화 
* MongDB 서버를 완전히 비어있는 상태로 레플리카 셋에 투입하면 초기 동기화가 발생합니다. 
* 초기 동기화할 때 주의점
  * 초기 동기화 작업은 단일 스레드로 동작하기 때문에 상당한 시간 필요
  * 초기 동기화 작업은 중간에 멈췄다가 다시 시작하면 처음부터 다시 시작해야 함

#### 수동 초기 동기화
* 다른 정상적인 레플리카 멤버의 데이터 파일을 그대로 복사해옵니다.
  * 복사시 기본 멤버가
* 이렇게데이터를 복사하고 초기 동기화를 수행하는 방식을 부트스트랩이라고 합니다. 

#### 자동 초기 동기화 
* 별다른 작업을 하지 않아도 백업을 수행합니다. 
* 너무 큰 데이터에 대해서 자동 초기 동기화를 수행하면 오랜 시간이 걸리기 때문에 수동 초기 동기화를 추천합니다. 

### 실시간 복제(Replication)
* 세컨더리 멤버는 OpLog 수집을 위한 백그라운드 스레드(Observer)가 복제 소스로 부터 OpLog를 가져와 Queue에 저장합니다.
  * Queue사이즈는 256MB의 제한을 가집니다.
* Replication 배치는 Queue에서 데이터를 가져와서 스레드 갯수에 맞춰서 작업을 나눈 다음에 작업을 요청합니다.
  * 동시 작업은 데이터를 `스킵 리스트`(버전 관리)로 관리하기 때문에 가능합니다.

#### 세컨더리 멤버의 읽기 일관성
* 세컨더리 멤버에서 OpLog에서 쿼리를 블록킹하는 이유는 아래와 같습니다. 
  * 프라이머리에서의 데이터 변경은 멀티스레드로 수행되고 세컨더리에서 OpLog의 재생또한 멀티 스레드로 수행되기 때문에 데이터 요청 처리 순서가 동일하게 유지 되는 것이 불가능합니다.
* 이와 같은 이유로 세컨더리에서는 OpLog를 재생할 때 이벤트를 특정 단위로 묶어서 한번에 재생하며 이때 쿼리의 블록킹이 수행됩니다.

## 복제 로그 설정
* MongDB의 OpLog는 파일이 아니라 큐처럼 작동하는 cap 컬랙션으로 관리됩니다. 
  * cap 컬랙션은 insert 만 허용합니다.
* OpLog는 최대 크기를 명시해야 하며 지정된 크기를 도달하면 데이터를 삭제해서 관리합니다. 

### OpLog 컬렉션 크기 설정 
* `oplog.rs` 크기가 중요한 이유는 세컨드리의 허용 가능한 지연시간이 결정됩니다. 
  * 만약에 세컨더리가 동기화 하지 못한 상태에서 primary의 `oplog`가 삭제 된다면 초기 동기화가 필요합니다. 
* Oplog의 컬렉션 크기를 명시적으로 설정하지 않으면 MongoDB 디스크의 FreeSpace의 5% 정도로 지정합니다. 
  * 최소 990MB에서 50GB이내에서 적용됩니다. 

### 레플리카 셋 멤버
#### 멤버 우선순위
* 우선 순위를 통해서 프라이머리가 될 수 있는 우선권 부여
  * 높을수록 좋습니다. 
#### 투표권
* 레플리카셋의 각 멤버는 0또는 1의 투표권을 가집니다. 
  
#### 히든 멤버
* 특정 멤버를 클라이언트에 숨길 때 사용합니다. 
  * 특정 멤버를 검증용으로 사용합니다. 

#### 지연된 복제
* NoSQL의 자체적인 데이터 복제의 경우에는 사용자의 실수에 대해서 해결법을 제공하지 않습니다. 
* 이러한 실수로부터 보호해주기 위해서 지연된 복제 기능을 제공합니다. 
  * 이러한 실수의 가장 좋은 복구 방법은 오프라인 백업은 별도로 유지하는 것이 좋습니다. 

### 레플리카 셋 배포
#### 레플리카셋 멤버
* 투표 가능한 최대 멤버수는 7이고 멤버는 최대 50개까지 가능합니다.
  * 너무 많은 멤버는 유지 비용이 많이 발생함(하트비트)
#### 홀수 멤버 유지
* 동일 고가용성(High Availability) 수준을 유지하는데 홀수가 유리합니다. 
  * 가용성(Availability) : 서비스가 중단없이 지속적으로 운영되는 것을 뜻함

#### 읽기 쿼리 분산
* 레플리카 셋의 멤버 추가의 대표적인 이유는 읽기 쿼리를 분산하기 위함입니다. 
* 세컨드리 멤버에서 데이터 읽기가 필요하다면 프라이머리에서 변경된 데이터가 동기화 되는 시간을 고려해야함
  * 만약 세컨더리의 복제 지연이 허용되지 않은 서비스라면 WriteConcern 옵션을 설정 해야 합니다.

#### 레플리카 셋 구성 
* 2개의 멤버 + 아비터 

|특징|설명|
|:--|:--|
|장점|서버 비용 절감|
|단점|백업을 위한 멤버 부족 - 물리적 백업을 위해서 세컨더리 셧다운시 프라이머리에 장애 발생시 Fail Over 불가, LVM 기능으로 스냅샷 진행 |
|단점|새로운 멤버를 추가할 때 여유 멤버 부족  |

* 3개의 멤버
  * 아비터 모드보다 구축 비용은 증가하지만 여유 서버 확보가 가능함
  * 중요한 서비스일수록 3개의 멤버로 구성합니다. 

#### 레플리카 셋의 이름
* 레플리카 셋의 이름은 유니크하게 관리하는 것이 좋습니다. 

#### DR(disater Recovery) 구성
* DR(재해 복구)는 하나의 IDC가 재해로 완전히 사용할 수 없는 상황이 됐을 때 다른 IDC에서 복제된 서버들로 복구 할 수 있도록 구성하는 것을 말합니다. 
* 여러개의 IDC에 걸쳐서 서버를 구성합니다. 

### 레플리카 셋 배포시 주의사항
#### 세컨드리 멤버의 장비 사향
* 세컨더리의 장비스펙은 최소한 oplog를 통해서 충분히 지연되지 않는 장비 사양(디스크 포함)을 준비해야 합니다. 
  * oplog 복제 지연으로 인한 시스템 리소스가 부족하면 하트 비트나 프라이머리 선출과정에 영향을 미칩니다.

#### 레플리카 셋 멤버의 네트워크 분산 
* 레플리카 셋을 구성할 때 각 스위치에다 분산해서 구성하는 것이 네트워크 스위치 장애 발생시 가용성을 유지할수 있는 방법입니다.