## 스토리지 엔진이란?
* 사용자의 데이터를 디스크와 메모리에 저장하고 읽어오는 역활을 담당(최적화도 담당)

## 스토리지엔진별 기능
|기능|MMAP|WiredTiger|RocksDB|TokuDB|
|:--|:--|:--|:--|:--|
|잠금수준|collection|document|document|document|
|데이터구조|b-tree|b-tree|LSM|Fractal-Tree|
|빌트인캐시|X|O|O|O|
|세컨더리인덱스|O|O|O|O|
|데이터압축|X|O|O|O|
|인덱스압축|X|O|O|O|
|암호화|X|O|X|X|
|인메모리지원|X|O|X|X|
|컬렉션파티션|X|X|X|O|

## 스토리지 엔지 혼합 사용
* 하나의 인스턴스에서 여러 스토리지 엔진을 복합적으로 사용할 수 없음
* 하지만 레플리카 셋의 각 인스턴스들이 다른 스토리지 엔진을 사용 할 수 있음

## mongoDB 데이터 폴더 위치
* /var/lib/mongodb

## MMAPv1 스토리지 엔진 특징
* 초창기에 사용되던 스토리지 엔진
* 자체적인 캐시가 없기 때문에 운영체제의 캐시 활용
  * 시스템 콜을 통한 오버헤드 발생
  * 안정적이지 않은 운영체제 캐시(페이지관리 및 dirty page문제)
  * dirty page란?
    * 메모리에는 데이터가 변경되었지만 아직 디스크로 동기화되지 앟는 페이지를 dirty page라고 함 
* 데이터 파일 프레그멘테이션
  * mongoDB에서 프레그멘테이션(단편화
    * 컬렉션 삭제시 빈공간을 기록해두고 새로운 도큐먼트가 추가되면 저장 할 위치를 찾습니다. 
    * 만약 작은 공간이 재활용 되지 못한다면 실제 데이터 파일의 크기가 실제 저장된 document보다 커짐
  * `storageSize`와 `size` 차이를 비교하면 쉽게 계산됩니다.
  * 프레그멘테이션이 크다면 컴팩션을 이용해서 공간을 줄이는 것이 좋습니다.
```js
mongo> use databasename
mongo> db.runCommand({ collstats : "users"})
{
  ...
  "ns" : "users.users",
  "count" : 25345,
  "size" : 1393945,
  "avgObjSize" : 580,
  "storageSIze" : 2913999,
  "paddingFactor" : 1
  ...
}
```

## WiredTiger 스토리지 엔진
* Berkeley DB 개발자들에 의해서 개발된 임베디드 DB 엔진으로 2014년 12월에 MongoDB에 인수되고 default 엔진이 됨
* Lock-free 알고리즘을 위해서 Hazard-Pointer나 Skip-List와 같은 많은 신기술 채택함, MVCC(잠금없는 데이터 읽기)

### WiredTiger 스토리지 엔진 설정
WiredTiger 섹션에서는 engineConfig(전역), collectionConfig(컬렉션), indexConfig(인덱스) 옵션으로 범위로 설정값을 다르게 할 수 있음

#### storage 섹션
|이름|설명|
|:--|:--|
|dbPath|데이터 파일을 저장할 경로 설정. 저널로그 및 OpLog 모두 하위에 저장됨|
|indexBuildRetry|인덱스 생성시 비정상적으로 종료된 경우 서버 재시작시 인덱스 생성 자동 시작할지 여부|
|repairPath|서버를 --repair 옵션과 함께 시작할 때 데이터 복구 쓰레드가 사용하는 임시 디렉토리|
|directoryPerDB|MongoDB가 데이터베이스 단위로 디렉터리를 생성할지 여부|
|syncPeriodSecs|MongoDB의 대부분의 스토리지는 DIRECT-IO 사용안함. 주기적으로 dirty페이지를 디스크로 플러시하는 주기를 설정함|
|journal|MongoDB 서버의 저널 로그를 활성화 여부를 결정합니다. journal 로그(트랜젝션 로그)를 디스크에 기록하지 않음 |

#### 주로 변경하는 옵션

|이름|설명|
|:--|:--|
|engineConfig.cacheSizeGB|WiredTiger 스토리지 엔진의 공유 캐시가 어느 정도의 메모리를 사용할지 설정. 기본적으로 장착된 메모리의 약 50 ~ 60%로 설정 |
|collectionConfig.blockCompressor|엔진의 데이터 파일을 압축할 것인지 어떤 알고리즘을 사용할 것인지 설정 "snappy", "zlib" |
|indexConfig.prefixCompression| WiredTiger의 인덱스는 데이터 블록 단위의 압축은 지원하지 않음, 프리픽스압축을 지원함|

#### WiredTiger 스토리지 저장방식
* 레코드 스토어
  * 일반적인 RDBMS가 사용하는 저장 방식. 테이블의 레코드를 한꺼번에 저장하는 방식
  * 기본적으로 `B-Tree` 알고리즘을 사용합니다. 
* 컬럼 스토어
  * 대용량의 분석 용도로 자주 사용됨
  * 레코드와 상관 없이 컬럼 단위 또는 컬럼 그룹 단위로 데이터 파일을 관리함
  * 특정 컬럼 단위로 데이터 파일을 생성함으로 테이터 파일이 작아지고 테이블 전체의 데이터를 읽어 들이는 시간이 빨라짐
* LSM(Log Structured Merge tree) 스토어
  * HBase나 카산드라 같은 NoSQL데이터 베이스에서 자주 사용하는 방식 
  * 데이터 읽기보다는 쓰기에 집중한 저장 방식 
  * 내부적으로 B-tree가 사용되지 않고 순차 파일 형태로 데이터를 저장함
  * LSM은 메모리에 저장 가능한 크기의 조각으로 데이터 파일을 관리하는 데 메모리의 한계를 넘어서면 디스크로 저장
  * 디스크로 처음 저장된 파일을 Level-0이라 하고 Level-0 데이터 파일 조각이 많아지면 이들을 모아서 Level-1 데이터 파일 생성 
  * 이렇게 로그 처럼 계속해서 기록되는 파일을 병합해서 Level-n까지 성장하는 방식으로 작동해서 로그 기반 병합 트리라고 불림
  * LSM이 도입된 이유는 대용량의 Insert를 문제없이 처리할 수 있는 솔루션이 필요해졌기 때문 
    * 기존의 B-tree는 대량이 insert될때 B-tree가 커져서 비용이 증가함

#### WiredTiger 데이터 파일 구조
* mongod.conf -> dbPath: /var/lib/mongodb 에 위치
* WiredTiger 파일 
  * 스토리지 엔진의 버전 정보 저장
* sizeStorer.wt 파일
  * 컬렉션의 전체 도규먼트 건수와 컬렉션의 데이타 파일의 크기를 관리하는 메타 데이터 파일
  * 도큐먼트 건수를 확인하는 쿼리는 디스크를 읽지 않고 빠르게 조회 가능
  * 샤딩된 환경이나 document를 읽어버리거나 MongoDB서버가 비정상 종료된 경우 일치하지 않을 수 있음
    * 정확한 count를 알고 싶다면 조건이 있는 count사용
* WiredTiger.lock 파일 
  * MongoDB서버가 사용하는 데이터 파일을 다른 MongoDB서버 인스턴스가 동시에 사용하지 못하도록 잠금 역활을 함
  * 추가적으로 WiredTiger가 정상적으로 셧다운 되었는지 판단하는데 사용됨 
* WiredTiger.turtle 파일
  * WiredTiger 스토리지 엔진의 설정 내용을 담고 있음
  * db.serverStatus 명령으로 조회 가능 
  * WiredTiger 스토리지 엔진이 작동하기 위한 기본적인 설정 `백업` 포함되어야 함
* WiredTiger.wt 파일
  * WiredTiger 스토리지 엔진의 메타 데이터를 저장하는 컬렉션의 데이터 파일
  * WiredTiger는 모든 컬렉션과 인덱스에 대해서 별도의 데이터 파일을 할당(`MMAPv1과 다름`)
* _mdb_catalog.wt
  * MongoDB 서버가 가지고 있는 컬렉션과 인덱스 목록고 각 인덱스나 컬렉션에 사용 사용하는 데이터 목록을 관리하는 메타 데이터 
* WiredTigerLAS(Look Aside Table).wt
  * WiredTiger 스토리지 엔진의 이빅션(Eviction - 축출) 서버는 메모리가 모자르게 되면 캐시에서 제거해야하는 데이터 페이지들이 
  * 더티 페이지 상태여서 디스크에 기록해야 할 때 필요하다면 이 파일을 사용해서 기록합니다. 
* diagnostic.data
  * mongo는 내부적으로 아래와 같은 정보를 1초에 한번씩 별도의 파일로 저장합니다.
    * 운영체제의 정보 (proc/stats)
    * serverStatus
    * replSetGetStatus
    * local.oplog.rs.stats 컬랙션의 collStat
    * buildInfo
    * getCmdLineOpts
    * hostInfo
  * 수집된 데이터를 FTDC(Full Time Data Capture)라고 함

#### WiredTiger의 내부 작동 방식 
* WiredTiger 스토리지 엔진은 트랜젝션을 지원하는 대부분의 RDBMS와 흡사한 내부 구조로 되어 있음
* MongoDB는 트랜젝션이 지원하지 않음 -> 하지만 WiredTiger는 트랜젝션을 지원함
* 다른 DBMS구조와 마찬가지로 `B-Tree` 구조의 데이터 파일과 서버 크래시 복구를 위한 `저널 로그(Write Ahead Log)`를 가지고 있음
  * 미리 3 ~ 10 journal 파일을 생성해둠
* 저널 관련 옵션 설정
```js
storage :
  journal : 
    enabled : true

  engine : wiredTiger

  wiredTiger:
    engineConfig:
      cacheSizeGB : 10
      configString : "log=(archive=true, enabled=true, file_max=100MB, path=/log/journal)"
    collectionConfig:
      blockCompressor : snappy
```
* configString 옵션 정보
  * enable : WiredTiger의 스토리지 엔진 저널을 활성화 할 것인지 여부
  * archive : WiredTiger 스토리지 엔진에서는 체크 포인트 이전의 저널 로그는 자동으로 삭제, 이렇게 삭제한 로그를 아카이빙(데이터보존)하여 다른 용도로 사용하는 경우
  * file_max : 저널 로그 파일의 최대 크기 설정
  * path : MongoDB는 기본적으로 저널 로그의 경로 설정 

* WiredTiger 스토리지는 내장된 공유 캐시를 가지고 있음
  * 인덱스나 데이터 파일을 캐시에서 빠르게 접근 가능하며 데이터 변경을 모아서 한번에 디스크로 기록하는 쓰기 배치 기능을 가집니다. 
* 데이터 변경 작동 방식
  * 사용자 데이터 변경 요청
  * 트랜젝션 시작 -> 커서를 변경해서 도큐먼트 내용 변경 
  * 공유 캐시에 적용, 저널 로그에 기록 -> 사용자에게 리턴 
  * 디스크에 기록
* WriteConcern 옵션에 따라서 달라질 수 있지만 기본적으로 저널에 기록되는 시점이 결과를 반환하는 시점입니다.
* 공유 캐시에 더티 페이지가 쌓이면 모아서 디스크에 기록합니다.
  * 이때 메모리의 더티 페잊는 원본과 병합작업이 거치는데 WiredTiger의 리컨실리에이션 모듈이 이 작업을 실행합니다.
* WiredTiger 스토리지 엔진의 데이터 블록은 모두 가변 사이즈입니다. (일반적인 RDBMS는 고정적)
  * 블록 크기의 상한선은 있지만 실제 데이터 블록의 크기는 고정적이지 않습니다. 
  * 고정적인 경우에는 압축 기능을 구현하기 어려움 -> 압축된 결과를 고정적인 블록에 저장(비효율 발생)
  * 가변적인 경우에는 위의 문제 없음 -> 압축 기능이 기본 옵션
  * 하지만 가변적인 경우에는 변경된 블록의 데이터를 다시 기록할 때 적절히 빈 공간을 찾는 알고리즘이 중요함
    * 즉 파편화가 발생될 가능성이 높음

#### 공유 캐시
* mongoDB의 사용자의 쿼리는 공유 캐시를 거치지 않고 처리 할 수 없음 
* 공유 캐시 최적화는 mongoDB의 처리 성능에 있어서 중요한 역활을 담당한다. 
* 스토리지 엔진의 공유 캐시 크기는 장착된 메모리의 50%로 설정됩니다.
* 공유 캐시는 MongoDB 서버를 재시작 하지 않고 크기를 조정할 수 있습니다.
  * 하지만 캐시 조정은 스토리지 엔진에 많은 내부 작업을 수행하게 합니다.(사용량 낮을때만)
* 일반적인 RDBMS는 디스크에 저장된 데이터 페이지를 이미지 그대로 캐시에 적재
  * 페이지 번호를 통해서 접근하기 때문에 실제 메모리로 매핑하는 작업을 수행
  * 인덱스 별도 관리
* WiredTiger 스토리지 엔진의 공유 캐시는 메모리 주소(C/C++ Pointer)로 직접 접근 방식
  * 인덱스를 별도 관리 하지 않고 공유 캐시 메모리에 적재할 때 레코드 인덱스 새롭게 생성
  * RDBMS에 비해서 메모리에 적재하는 비용은 크지만 적재된 메모리를 사용하는 비용은 효율적입니다. 
* WiredTiger 스토리지는 공유 캐시 잠금 경합을 최소화하기 위해서 Lock-Free 알고리즘 사용
  * 하자드 포인터
  * 스킵 리스트

#### 하자드 포인터 
* 사용자 스레드 : 쿼리를 수행하기 위해 캐시를 접근하는 스레드
* 이빅션 스레드 : 캐시에서 빈 공간을 만드는 역활을 하는 스레드 
* 사용자 스레드와 이빅션 스레드는 하자드 포인터를 통해서 접근하거나 지우려는 정보를 공유합니다. 
* 하자드 포인터의 최대 갯수는 기본값으로 1000개로 설정됨. 더 큰값으로 지정할 수 있음
```js
...
  engine : wiredTiger
  wiredTiger:
    engineConfig:
      cacheSizeGB : 10
      configString : "hazard_max=2000"
```
#### 스킵 리스트(Skip-List)
* B-Tree와 비슷한 log(n) 성능을 가지며 B-tree보다는 조금 느립니다.
* 스킵리스트는 새로운 노드를 추가할 때 별도의 잠금이 필요하지 않음. 삭제는 잠금이 필요
* 여러 스레드가 노드를 저장하거나 검색해도 잠금 경합이 필요하지 않음
* wiredTiger 엔진은 언두 로그를 스킵 리스트로 관리합니다.(변경 이후의 데이터를 저장)
  * 데이터가 변경되도 데이터 페이지를 직접 변경하지 않고 스킵 리스트에 쌓아 둡니다. (쓰기 처리 향상)
* 이러한 방식을 지원하기 때문에 동시 처리 성능이 향상됨 

#### 캐시 이빅션
* MongoDB 공유 캐시를 위해서 지정된 크기의 메모리 공간만 사용해야 합니다.
* 요청을 빠르게 응답하기 위해서 메모리 공간을 효율적으로 관리합니다. 
* 이빅션 서버는 사용자 요청 스레드와 별개의 백그라운드 스레드로 실행됩니다. 
  * 공유 캐시에 적대된 데이터 페이지중에서 자주 사용되지 않은 데이터 페이지 위주로 공유 캐시에서 제거하는 작업을 수행합니다. 
  * 만약 백그라운드 이빅션 스레드가 적절히 공유 캐시의 여유 공간을 확보하지 못하면 포그라운드 스레드에서 직접 캐시 이빅션을 실행합니다. 
  * 해당 매트릭 정보를 그래프화해서 모니터링 하는 것이 좋습니다. 

#### 체크 포인트 
* WiredTiger 스토리지 엔진도 사용자의 요청을 빠르게 처리하면서 커밋된 트랜젝션의 영속성을 보장하기 위해서 `트랜젝션 로그`(WAL,저널 로그) 사용
* 트랜젝션 DBMS는 `체크 포인트`라는 개념을 가집니다. 
  * `체크 포인트`란 데이터 파일과 트랜젝션 로그가 동기화 되는 시점  
  * `체크 포인트`가 실행되어야 오래된 트랜젝션을 삭제하고 새로운 트랜젝션 로그를 덮어쓸수 있음
  * `체크 포인트`는 mongo가 비정상 종료되었다가 재시작되었을때 복구 할 시점의 기준이 됩니다. 
  * mongoDB는 `샤프 체크 포인트` 방식을 채택함
    * `샤프 체크 포인트`는 평상시에는 디스크 쓰기가 별로 많지 않지만 실행되는 시점에 한번에 모아서 더티 페이지를 기록함 
* 옵션
  * log_size 
    * 얼마나 자주 WiredTiger 스토리지 엔진 체크 포인트를 실행할 것인지 결정하는 옵션입니다. 기본값 0, 엔진이 결점
    * 옵션에 설정된 크기만큼 트랜젝션 로그 쓰기가 발생하면 체크 포인트를 실행합니다.
  * wait 
    * WiredTiger 스토리지 엔진이 지정된 시간동안 대기 했다가 주기적으로 체크 포인트를 실행하도록 합니다.
    * 초단위이며 기본 값은 0이면 wiredTiger가 체크 포인트 시점을 결정합니다.
  * name
    * 체크 포인트의 이름을 설정합니다. 별도로 설정하지 않는 것이 좋습니다. 

#### MVCC(Multi Version Concurrency Control)
* 하나의 레코드에 대해서 여러개의 버전을 동시에 관리하면서 적절한 버전을 사용하게 해주는 기술
* 데이터 변경이 들어오면 skip-list를 사용해서 최근 변경 점을 앞에 두도록 유지합니다. 
* 리스트가 계속 늘어나게 되면 안되기 때문에 memory_page_max 설정 값보다 큰 메모리를 사용하는 페이지를 찾아서 자동으로 디스크에 기록합니다. 
* 검색 커넥션의 트랜젝션 아이디에 따라서 결과 값이 달라집니다. 
* 기본 격리수준은 SNAPSHOT이며 mysql의 REPEATABLE-READ 와 같습니다. 
  
#### 데이터 블록
* WiredTiger 스토리지 엔진은 데이터를 고정된 크기의 블록을 사용하지 않습니다. 
  * 하지만 데이터 크기가 너무 커지는 것을 막기 위해서 하나의 페이지의 크기를 제한합니다. 
* mongoDB는 B-Tree의 인터널(브랜치) 노드와 리프 노드의 페이지 크기를 다르게 설정할 수 있습니다.
  * 인터널 노드는 리프 노드를 구분하는 인덱스값만 가짐
  * 기본값 인터널 노드 4KB, 리프 페이지 노드 32KB
* 컬렉션과 인덱스에 대해서 페이지 크기를 다르게 설정할 수 있습니다. 
* 데이터 블록 크기
  * 만약 대량의 INSERT와 분석이나 배치 작업을 위한 대량의 조회가 주요 접근 패턴이라면 페이지를 크게 가져가는 것이 좋습니다.
    * 인덱스 페이지 크기는 작게 가져가는 것이 좋습니다.
  * 소규모의 도큐먼트를 아주 빈번하고 랜덤하게 데이터를 읽고 변경한다면 작게 가져가는 것이 좋습니다.

#### 운영체제 캐시
* WiredTiger 스토리지 엔진은 내장된 공유 캐시를 가지고 있음
* 운영체제의 캐시를 경유하는 Cached IO를 기본 옵션으로 사용하고 있음
  * mongoDB는 더블 버퍼링(`Double Buffering`) : 리눅스 커널 페이지 로드 -> WiredTiger 스토리지 엔진 내장 캐시에 저장
* 더블 버퍼링을 사용하지 않으려면 Direct IO를 사용 해야 합니다.
  * Direct IO를 사용하려면 블록의 크기가 고정적이어야 합니다. 

#### 압축
* 일반적으로 MongoDB의 컬랙션은 압축이 필수적입니다.(key value 값의 반복이 많기 때문에 효율이 좋음)
  * 인덱스는 일반 RDBMS와 마찬가지로 인덱스 키 엔트리 구조이기 때문에 압축이 효율적이지 않기 때문에 압축 적용되지 않음
* WiredTiger 스토리지는 데이터 입출력 레이어에서 압축을 지원합니다. 
  * 가변 사이지의 페이지 사용
  * 다양한 압축 알고리즘 지원
* 고정된 크기의 페이지를 사용하는 경우 압축 결과도 고정된 크기의 페이지로 생성되어야 낭비가 없습니다. 
* WiredTiger 스토리지 엔진이 데이터를 읽고 쓰는 시점에서 데이터의 압축과 해제가 처리됩니다. 
* WiredTiger 스토리지 엔진은 네가지 형태의 압축 기능을 제공
  * 블록 압축 - mongoDB 사용 가능(기본 값)
  * 인덱스 프리픽스 압축 - mongoDB 사용 가능
  * 사전 압축
  * 허프만 인코딩
* 압축 타입
  * snappy - 기본 압축
    * LZ4가 업데이트 되면 사용 필요
  * zlib, zstd(압축률이 가장 좋고 속도 어느정도 나옴)
* 컬렉션과 인덱스, 저널 로그에 대해서 압축을 지정할 수 있음
* 더블 버퍼링에서의 압축 적용
  * 리눅스 페이지 캐시에는 압축된 페이지가 저장
  * WiredTiger 캐시에는 압축 해제된 페이지가 저장됨 