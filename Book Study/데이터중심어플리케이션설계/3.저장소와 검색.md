# 저장소와 검색
* 데이터 베이스의 기본적인 작업은 데이터를 저장하고 데이터를 요청하면 다시 데이터를 전달하는 것입니다. 
* 그렇다면 데이터 베이스 입장에서 어떻게 해당 기능을 제공하는지 알아봅니다. 
* 이번장에서는 관계형 DB와 NOSQL의 저장소 엔진에 대해서 알아봅니다.
* 추가로 로그 구조계정의 저장소 엔진과 페이지 지향(B-tree같은) 계열 저장소 엔진을 검토합니다.
  
## 데이터베이스를 강력하게 만드는 데이터 구조
* 많은 데이터 베이스는 append-only 데이터 파일인 log를 사용합니다. 
  * log를 구현하기 위해서는 동시성 제어, 로그 크기 제어를 위한 회수 작업, 오류 처리 부분 기록된 레코드 처리등의 문제가 해결되어야함
  * log라는 단어는 애플리케이션에서 무슨일이 일어났는지 기술한 정보입니다. 
* 데이터 베이스에서 매번 값을 찾을 때마다 full scan을 하게 되면 데이터가 많은 경우 성능이 매우 감소합니다. 
* 데이터 베이스에서 특정 키를 효율적으로 찾기 위해서 index를 사용합니다. 
* index는 일반적으로 부가적인 메타 테이터를 유지합니다. 
  * mysql의 index page같이 데이터의 위치를 찾는데 도움을 줍니다. 
* index는 데이터 베이스의 값에는 영향을 미치지 않고 질의 성능에만 영향을 줍니다. 
* index는 특히 쓰기 과정에서 오버헤드가 발생합니다 
  * 왜냐하면 데이터를 쓸때 마다 인덱스도 업데이트 해주기 때문입니다. 
* 그러므로 인덱스를 선택할 때는 최소한의 비용으로 최대의 이익을 안겨줄수 있는 선택을 하는 것이 중요합니다. 

### 해시 색인
* 일반적으로 key-value 데이터는 해시 맵을 통해서 구현합니다. 
#### 파일의 바이트 offset을 이용한 해시 맵
* append-only를 통해서 데이터를 관리한다고 하면 key를 파일의 바이트 offset과 매핑해서 인메모리 해시 맵을 유지 할 수 있음
* 파일에 새로운 key-value가 추가 될 때마다 기록한 데이터의 offset을 기록하기 위해서 해시 맵 갱신 필요
* 이 방식은 매우 단순해보이지만 실제로 많이 사용하며 비트캐스크(Riak의 기본 저장소)의 근본적인 방식임
  * 비트 캐스크는 해시 맵을 전부 메모리에 유지하 때문에 사용 가능한 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기 쓰기를 보장함.
  * 비트 캐스크 같은 엔진 저장소는 key의 value가 자주 갱신되는 상황에 적합합니다. 
    * key : 고양이 동영상의 url, value : 동영상 클릭 회수
    * 작업부하에 value의 쓰기 작업은 많지만 key는 많지 않은 경우입니다.
#### append-only log에서 디스크 공간
* append-only를 통해서 log를 생성한다면 디스크 공간의 부족이 발생합니다.
* 이를 위한 해결방안은 다음과 같습니다.
  * log가 특정 크기에 도달하면 파일을 세그먼트 단위로 나눕니다.
  * 세그먼트에 compaction을 수행합니다. 
    * compaction이란 log에서 중복된 값을 버리고 키의 최신 업데이트 값만 유지하는 것을 말합니다. 
    * 예를 들어 로그에 click이라는 key에 value가 1, 3, 6, 8, 10라고 순차적으로 기록되었다면 {"click" : 10} 만 남겨 기록하여 크기를 줄입니다. 
  * compaction된 세그먼트 파일을 병합합니다. 
  * 위의 작업들은 백그라운드 스레드를 통해서 수행할 수 있습니다. 
  * 작업을 수행하는 동안 컴팩션하기 전의 파일을 기반으로 동작할 수 있기 때문에 서비스에 중단없이 수행 가능합니다. 
  * redis에서 AOF는 위와 같이 동작합니다. 
* 구현시 고려해야 하는 사항
  * 파일 형식
    * 바이트 단위의 문자열 길이를 부호화한후 원시 문자열을 부호화하는 바이너리 형식이 빠르고 간단
  * 레코드 삭제
    * 키과 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드(tombstone)를 추가해야 함
  * 고장 복구
    * 데이터 베이스가 재시작되면 인메모리 해시 맵은 손실됨
    * 원칙적으로 전체 세그먼트 파일의 full scan해서 각 키에 대한 최신 값을 확인해서 해시맵을 복원 할 수 있습니다. 
    * 너무 큰 세그먼트의 경우 시간이 오래 걸리 수 있기 때문에 빠르게 복구하기 위한 스냅샵을 디스크에 저장해서 복구 속도를 높입니다. 
  * 부분적으로 레코드 쓰기
    * 데이터 베이스가 로그에 레코드를 추가하는 도중에 죽을 수 있기 때문에 손상된 로그를 체크섬을 통해서 무시 할 수 있음
  * 동시성 제어
    * 쓰기 작업의 일반적인 구현은 하나의 쓰레드를 통해서 구현함
    * 읽기 작업은 다중 스레드로 접근이 가능함
* update방식 대신 append-only 로그를 사용하는 이유
  * 추가 및 순차적인 쓰기 작업이라서 무작위 쓰기보다 훨씬 빠름
  * 동시성과 고장 복구가 훨씬 간단합니다. 
    * 예를 들어 로그를 update하다가 죽는 경우에 대한 걱정이 필요 없음
    * append-only의 경우 이전의 기록과 새로운 기록이 모두 남기 때문
  * 오래된 세그먼트 병합은 조각화되는 데이터 파일 문제를 피할 수 잇음
* 해시 테이블 인덱스의 제한사항
  * 해시 테이블을 메모리에 저장해야 하기 때문에 키가 너무 많은 경우 문제가 된다.
    * 디스크에 해시 테이블을 유지관리하게 되면 무작위 접근 I/O 및 디스크 확장 비용등등 다양한 문제 발생
  * 해시 테이블은 범위 질의에 효율적이지 않습니다. 

### SSTable과 LSM 트리
#### SSTable(Sorted String Table)
* 앞에서 설명한 key-value의 세그먼트 파일의 내부 데이터를 key를 기준으로 정렬한 것을 SSTable이라고 부릅니다. 
* SSTable로 병합된 세그먼트에는 각 키가 한번만 나타나야합니다.(compaction 과정 적용)
#### 해시 인덱스에 비해서 SSTable이 가진 장점
* 세그먼트의 병합이 간단하고 효율적입니다. 
  * 순차적으로 정렬되어 있기 때문에 첫번째키부터 순차적으로 동작할 수 있습니다. 
* 파일에서 특정 키를 찾기 위해서 더는 메모리에 모든 키의 색인을 유지할 필요가 없습니다. 
  * 특정 key를 인메모리 인덱스에 찾지 못한다 하여도 SSTale이 정렬되어 있으므로 가장 가까운 값을 찾아서 범위를 scan하면 값을 찾을 수 있습니다. 
    * 이러한 검색을 지원하기 위해서 희소 인덱스가 필요합니다. 
    * 예제) 만약 "H"라는 값을 찾기
      * 희소인덱스 : [A, E, J, M, Q, U]
      * 동작 : E부터 J 구간을 스캔해서 H값을 Find
* 읽기 요청은 요청 범위내에서 여러 key-value를 스캔하기 때문에 해당 레코드를 그룹화하고 압축해서 관리합니다. 
  * 희소 인덱스는 압축된 블록의 시작을 가르킵니다. I/O 대역폭도 이득
#### SSTable 생성과 유지 
* 쓰기 작업이 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조에 추가
  * 이 인메모리 트리를 멤테이블(memtable)이라고 합니다. 
* 멤테이블이 일정 크기가 되면 SSTable 파일로 디스크에 기록합니다. 
* 기록된 SSTable은 데이터베이스의 가장 최신 세그먼트가 됩니다. 
* SSTable을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록합니다. 
* 읽기 요청이 들어오면 멤테이블을 검색하고 없다면 디스크의 가장 최신 세그먼트를 검색 -> 두번째 세그먼트 -> 세번쨰 세그먼트 ...
* 가끔 세그먼트 파일을 합치는 병합과 컴팩션 과정을 수행합니다.(백그라운드 동작)
* 멤테이블의 경우 인메모리이기 때문에 가장 최신 쓰기가 손실되기 때문에 매번 쓰기를 즉시 추가할 수 있는 로그가 유지관리되어야 하며 SSTable이 디스크로 쓰여지는 순간 제거되도 되며 정렬되어 있지 않아도 됩니다. 
#### LSM 트리 성능 최적화
* LSM 트리는 존재하지 않은 키를 검색하는 경우 느릴 수 있습니다.
  * Level0(멤테이블) ~ Level하위(세그먼트) 까지 모두 검색해야 하므로
* 이런 성능을 개선하기 위해서 Bloom Filter를 추가적으로 사용
* SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략이 있음
  * 크기 계층 컴팩션
    * 상대적으로 좀 더 새롭고 작은 SS테이블을 상대적으로 오래되고 큰 SS테이블에 연이어 병합합니다. 
    * HBase
  * 레벨 컴팩션
    * 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 "레벨"로 이동
    * 레벨DB, 록스 DB
  * 카산드라는 둘다 지원합니다. 
* 기본적인 LSM 트리의 개념은 백그라운드에서 지속적인 병합입니다.
#### 블룸 필터
* https://ko.wikipedia.org/wiki/%EB%B8%94%EB%A3%B8_%ED%95%84%ED%84%B0
* 원소가 집합에 속하는지 여부를 검사하는데 사용되는 확률적 자료 구조
* 긍정 오류는 발생가능하나 부정 오류는 발생되지 않는 것을 기반으로 함
  * 긍정 오류 : 어떤 원소가 집합에 속한다고 판단되지만 원소는 집합에 속하지 않는 오류
  * 부정 오류 : 원소가 집합에 속하지 않는다고 판단되었지만 원소가 집합에 속하는 오류

https://hyunki1019.tistory.com/89

#### LSM(log struct merge)tree 위키 번역
* https://en.wikipedia.org/wiki/Log-structured_merge-tree
* 컴퓨터 과학에서 LSM tree는 트랜잭션 로그 데이터와 같이 insert 가 많은 파일에 대한 인덱스된 액세스를 제공하는 데 매력적인 성능 특성을 가진 데이터 구조입니다. 
* 다른 검색 트리와 마찬가지로 키-값 쌍을 유지합니다.
* LSM tree는 기본 저장매체에 최적화 된 두개 이상의 분할된 structure에 데이터를 유지합니다. 
* 데이터는 배치를 통해서 두 structure사이에서 효율적으로 동기화됩니다. 
* LSM 트리의 간단한 버전은중 하나는 2단계 LSM트리입니다. 
* 패트릭 오닐이 설명 했듯이 2단계 LSM 트리는 C0, C1이라는 두개의 트리 유사 구조로 구성됩니다.
* C0은 더 작고 완전히 메모리에 위치하고 C1은 디스크에 위치합니다.
* 새 레코드가 들어오면 C0 구성 요소에 삽입되고 그 영향으로 C0이 특정 임계값이 되면 디스크의 C1에 병합됩니다. 
* LSM 트리의 성능 특성은 각 구성요소가 기본 저장매체의 특성에 맞게 조정됩니다. 
* 데이터는 병합 정렬을 연상시키는 알고리즘을 사용해서 롤링 배치로 미디어간에 효율적으로 마이그레이션 됩니다. 
* 실제로 사용되는 대부분의 LSM트리는 다양한 level을 사용합니다. 
* 레벨 0은 메인 메모리에 보관되며 트리를 사용해서 표현할 수 있습니다. 
* 디스크 위의 데이터는 정렬된 데이터로 구성됩니다. 
* 개별 수행 작업에는 인덱스 키별로 정렬된 데이터가 포함됩니다. 
* run은 디스크에서 하나의 파일로 표현되거나 키 범위가 겹치지 않은 파일 모읍으로 표현됩니다. 
* 특정 키에 대한 쿼리를 수행하기 위해서 레벨 0 트리에서 검색하고 각 실행을 수행해야 합니다.
* 번역 위치 : A particular key may appear in several runs, and what that means for a query depends on the application. 
    

### 트랜잭션 처리나 분석 
* 초창기의 비즈니스에서 데이터 베이스의 사용은 `커머셜 트랜잭션(commercial transaction)`이었기 때문에 트랜젝션 용어는 변하지 않고 쓰임
  * 트랜젝션 : 논리 단위 형태로써 읽기와 쓰기 그룹을 뜻함
* `온라인 트랜젝션 처리(online transaction processing, OLTP)`
  * index를 사용해서 적은 수의 레코드를 찾고 수정하거나 삽입함
* `온라인 분석 처리(online anlytic processing, OLAP)`
  * 많은 수의 레코드를 스캔해서 일부 컬럼마 읽어서 집계 통산(count, sum, avg)
* OLAP을 위한 개별 데이터 베이스를 구성하는 것을 `데이터 웨어 하우스(data warehouse)`라고 부름

|특성|OLTP|OLAP|
|:--|:--|:--|
|주요 읽기 패턴|질의당 적은 수의 레코드, 키 조회|많은 레코드에 대한 집계 |
|주요 쓰기 패턴|임의 접근, 낮은 지연 시간으로 기록|대규모 블러오기(bulk import, ETL) 또는 이벤트 스트림|
|주요 사용처|웹 어플리케이션을 통한 최종 사용자/소비자|의사결정 지원을 위한 내부 분석가|
|데이터 표현|데이터의 최신상태|시간이 지나면 일어난 이벤트 이력|
|데이터 셋 크기|기가바이트에서 테라바이트|테라바이트에서 페타바이트|

### 데이터 웨어하우징
* `데이터 웨어 하우스`는 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의 할 수 있는 개별 데이터 베이스를 말합니다. 
* OLTP 데이터 베이스에서 ETL을 통해서 데이터 웨어 하우스로 적재합니다. 
  * ETL : 데이터를 추출(extract)하고 사용하기 편한 스키마로 변환(transform)하고 적재(load)하는 것을 뜻합니다.
* 데이터 웨어 하우스 벤더 : 아마존 레드시프트, SOL-on-Hadoop, 아파치 하이브, 스파크 SQL, 클라우데라 임팔라, 페이스북 프레스토, 아파치 타조, 아파치 드릴
  * 이중 일부는 구글의 드레멜에서 가져온 개념을 기반으로 함
* 많은 데이터 하우스는 `star schema(차원 모델링)`로 알려지 정형화된 방식을 사용합니다. 
  * star schema는 이벤트가 발생한 A 라는 테이블이 있고 A의 개별 컬럼들이 다른 테이블의 외래키를 참조하는 구조로 구성됩니다. 
  * 예를 들어 식료품 판매 DB의 경우 A테이블은 개별 판매 기록이 되고 각 컬럼들은 언제, 누가, 무엇, 어떻게, 왜 삿는지에 대한 테이블을 참조로 구성합니다. 
  * `눈꽂송이 모양 스키마`는 star schema보다 한차원 더 깊게 들어가는 것을 말합니다. 

### 컬럼 지향 저장소
* 일반적인 웨어 하우스 질의는 한 번에 4개 또는 5개의 컬럼만 접근합니다. 
  * 분석용으로는 `SELECT *`의 질의가 거의 필요하지 않습니다. 
* 대부분의 OLTP 데이터 베이스는 `로우 지향 방식`으로 데이터를 배치합니다. 
* `컴럼 지향 저장소의 기본 개념`은 모든 값을 로우에 함께 저장하지 않고 각 칼럼 별로 값을 저장합니다. 
  * 각 컬럼을 개별 파일에 저장하면 질의에 사용되는 컬럼만 읽고 구분 분석하면 됩니다. 

#### 컬럼 압축
* 컬럼 지향 저장소는 반복되는 값이 나타날 확률이 높기 때문에 압축에 효율적이며 다양한 방법이 제공됩니다. 
* 비트맵 부호화 방식 
  * 보통 컬럼에서 고유 값의 수는 로우 수에 비해 적습니다.
    * 예를 들어 다음과 같은 값을 가진 컬럼은 `1,1,4,3,2,1,1,2,3,4` 은 4개의 고유값(1,2,3,4)을 가집니다.
  * 각 값에 대한 비트 맵을 만들고 런 렝스 부호로 관리할 수 있습니다. 

### 메모리 대역폭과 벡터화 처리
* 수백만 로우를 스캔하는 데이터 웨어 하우스의 질의는 디스크에서 메모리로 데이터를 가져오는 부분이 병목임
* 또한 분석용에서는 메모리에서 CPU 캐시로 가는 대역폭을 효율적 사용하는 것과 분기예측실패과 버블을 피하고 단일 명령 다중 데이터(SIMD)를 사용하도록 신경 써야합니다.

### 컬럼 저장소의 순서 정렬
* 컬럼 저장소는 로우를 재구성 해야 하기 때문에 개별 컬럼들의 독자적으로 정렬할 수 없습니다. 
* 정렬 키를 지정하면 해당 컬럼을 기반으로 데이터를 정렬합니다. 
  * 정렬 키는 쿼리 조회시 가장 효율적으로 사용할 수 있는 키를 기반으로 합니다. 
* 정렬된 데이터는 압축 효율을 증가시킵니다.(동일한 값의 반복 증가)
  
### 다양한 순서 정렬
* 컬럼 기반 데이터 베이스도 다양한 순서로 정렬 할 수 있습니다.
* 버티카에서는 복제 장비에서 다양한 방식으로 정렬에서 데이터를 저장합니다. 

### 컬럼 저장소에 쓰기
* B트리와 같은 방식은 압축된 컬럼에 적용이 불가능합니다.
* LSM 트리를 통해서 인메모리 저장소 -> 디스크에 쓰는 형식으로 진행함

#### 집계 : 데이터 큐브 와 구체화 뷰